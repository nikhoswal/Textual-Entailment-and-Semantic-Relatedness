{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Semantic_Relatedness_Final.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "EOqySLsaQ4bq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install ggplot\n",
        "from __future__ import print_function\n",
        "%matplotlib inline\n",
        "\n",
        "from IPython.display import Image, display\n",
        "from io import BytesIO\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "from os.path import join, exists\n",
        "import sys\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "import urllib2\n",
        "import json\n",
        "from zipfile import ZipFile\n",
        "\n",
        "import pandas as pd\n",
        "import pydot_ng as pydot\n",
        "import graphviz\n",
        "from ggplot import *\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.utils import to_categorical, plot_model\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.layers import Embedding, Dense, Input, Dropout, Reshape, BatchNormalization, TimeDistributed, Lambda, Layer, LSTM, Bidirectional, Convolution1D, GRU, add, concatenate\n",
        "from keras.callbacks import Callback, ModelCheckpoint, TensorBoard, BaseLogger, ReduceLROnPlateau\n",
        "from keras.optimizers import RMSprop, Adam, SGD, Adagrad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bjJLxQelQ4bt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_sample_size = 1000 # Change this to -1 if you want all\n",
        "max_seq_length = 20 # max 400\n",
        "\n",
        "model_name = 'small'\n",
        "\n",
        "lr = 0.001\n",
        "lr_decay = 1e-4\n",
        "epochs = 10\n",
        "batch_size = 32\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JQCAG3eMQ4b2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Download GloVe"
      ]
    },
    {
      "metadata": {
        "id": "NcD8RcySMg7K",
        "colab_type": "code",
        "outputId": "df833d44-956e-4216-ec51-de3f8cb394d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "glove_url = 'http://nlp.stanford.edu/data/glove.840B.300d.zip'\n",
        "embedding_dim = 300\n",
        "glove_filename = 'glove.840B.' + str(embedding_dim) + 'd.zip'\n",
        "glove_loc = join(glove_filename)\n",
        "\n",
        "if not exists(glove_loc):\n",
        "    print('Download %s' % glove_filename)\n",
        "    get_file(glove_filename, glove_url, cache_dir='.', extract=True)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Download glove.840B.300d.zip\n",
            "Downloading data from http://nlp.stanford.edu/data/glove.840B.300d.zip\n",
            "2176770048/2176768927 [==============================] - 613s 0us/step\n",
            "2176778240/2176768927 [==============================] - 613s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oezA0xIkVhkY",
        "colab_type": "code",
        "outputId": "6dba7e87-2d2e-4b70-ac67-713f447f2deb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "glove_filename = os.path.join(\"datasets\", 'glove.840B.300d.txt')\n",
        "\n",
        "embeddings = {}\n",
        "\n",
        "print('Extract %s' % glove_filename)\n",
        "with open(glove_filename, 'r') as f:\n",
        "    for line in f:\n",
        "        values = line.split(' ')\n",
        "        word = values[0]\n",
        "        embedding = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings[word] = embedding\n",
        "        \n",
        "print('Embeddings size: %d' % len(embeddings))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extract datasets/glove.840B.300d.txt\n",
            "Embeddings size: 2196016\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FgKm3rvR5zht",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##**Loading Dataset**"
      ]
    },
    {
      "metadata": {
        "id": "WGCtPFBLSu9K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def readFile(fileName):\n",
        "  data = pd.read_csv(fileName, delimiter='\\t', header = None, skiprows=1)\n",
        "  data.columns = [\"pair_ID\", \"sentence_A\", \"sentence_B\", \"relatedness_score\", \"entailment_judgment\"]\n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pwqeaQNJSvAw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train = readFile('SICK_train.txt')\n",
        "test = readFile('SICK_test_annotated.txt')\n",
        "valid = readFile('SICK_trial.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pkhhw0-CSvDm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_df_features = train[['sentence_A','sentence_B']]\n",
        "textsValid = valid[['sentence_A','sentence_B']]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a5PmY9qeSvHF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "labels = train[\"relatedness_score\"]\n",
        "\n",
        "labelsValid = valid[\"relatedness_score\"]\n",
        "\n",
        "textsTest = test[['sentence_A','sentence_B']]\n",
        "labelsTest = test[\"relatedness_score\"]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VNyeNmUIXpVB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_sentence1 = train['sentence_A'].values.tolist()\n",
        "train_sentence2 = train['sentence_B'].values.tolist()\n",
        "\n",
        "valid_sentence1 = valid['sentence_A'].values.tolist()\n",
        "valid_sentence2 = valid['sentence_B'].values.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KoFGuW_i6TgR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## **Normalizing Target Value**"
      ]
    },
    {
      "metadata": {
        "id": "ahG02Lj6kzH6",
        "colab_type": "code",
        "outputId": "cd06a083-698e-4ecc-8bed-b3d15b738cd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "q = np.reshape(labels, (-1,1))\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(q)\n",
        "labels = pd.DataFrame(scaler.transform(q))\n",
        "\n",
        "w = np.reshape(labelsValid, (-1,1))\n",
        "scaler1 = MinMaxScaler()\n",
        "scaler1.fit(w)\n",
        "labelsValid = pd.DataFrame(scaler1.transform(w))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/numpy/core/fromnumeric.py:52: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
            "  return getattr(obj, method)(*args, **kwds)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "nKbmbLEqQ4ch",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Prepare Word Embeddings"
      ]
    },
    {
      "metadata": {
        "id": "okCOLHqoQ4ci",
        "colab_type": "code",
        "outputId": "15359be8-ca56-4b4b-c60f-9a49f09cb86c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "NUM_WORDS = len(embeddings) #200000\n",
        "\n",
        "print('Found %s samples.' % len(train_sentence1))\n",
        "\n",
        "train_sentences = train_sentence1 + train_sentence2\n",
        "valid_sentences = valid_sentence1 + valid_sentence2\n",
        "\n",
        "\n",
        "tokenizer = Tokenizer(num_words = NUM_WORDS)\n",
        "tokenizer.fit_on_texts(train_sentences)\n",
        "\n",
        "sentence1_word_sequences = tokenizer.texts_to_sequences(train_sentence1)\n",
        "sentence2_word_sequences = tokenizer.texts_to_sequences(train_sentence2)\n",
        "\n",
        "valid_sentence1_word_sequences = tokenizer.texts_to_sequences(valid_sentence1)\n",
        "valid_sentence2_word_sequences = tokenizer.texts_to_sequences(valid_sentence2)\n",
        "\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "print('Found %s unique tokens.' % len(word_index))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 4500 samples.\n",
            "Found 2184 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4QuNdxm4Q4cl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "embedding_dim = 300\n",
        "words_len = min(NUM_WORDS, len(word_index))\n",
        "# word_embedding_matrix = np.zeros((words_len + 1, embedding_dim))\n",
        "word_embedding_matrix = np.random.random((words_len + 1, embedding_dim))\n",
        "k = 0\n",
        "for word, i in word_index.items():\n",
        "    if i >= NUM_WORDS:\n",
        "        continue\n",
        "    embedding_vector = embeddings.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        word_embedding_matrix[i] = embedding_vector\n",
        "        k += 1\n",
        "        \n",
        "max_word_count_text = 0\n",
        "text_count = defaultdict(int)\n",
        "for sentence in sentence1_word_sequences:\n",
        "    max_word_count_text = max(max_word_count_text, len(sentence))\n",
        "    text_count[len(sentence)] += 1\n",
        "\n",
        "max_word_count_hypo = 0\n",
        "hypo_count = defaultdict(int)\n",
        "for sentence in sentence2_word_sequences:\n",
        "    max_word_count_hypo = max(max_word_count_hypo, len(sentence))\n",
        "    hypo_count[len(sentence)] += 1\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wgpYf-FDQ4cn",
        "colab_type": "code",
        "outputId": "63818558-7000-451b-a3a4-259b8576cf5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "mpl_fig = plt.figure()\n",
        "ax = mpl_fig.add_subplot(111)\n",
        "\n",
        "ax.bar(range(len(text_count)), text_count.values())\n",
        "ax.bar(range(len(hypo_count)), hypo_count.values(), alpha=0.7)\n",
        "\n",
        "plt.title(\"Sentence Length Distribution\")\n",
        "plt.xlabel(\"Length\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEVCAYAAAACW4lMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmAwkSZgMJEnAfwK3HBnVY5aKcQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "UzOSxQmvQ4cq",
        "colab_type": "code",
        "outputId": "3897c1f2-5c00-44ff-989e-078733ece324",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "print('Null word embeddings: %d' % (np.sum(np.sum(word_embedding_matrix, axis=1) == 0) - 1))\n",
        "print('Found %d' % k)\n",
        "print('Total: %d' % len(word_embedding_matrix))\n",
        "print('Max word text: %d' % max_word_count_text)\n",
        "print('Max word hypothesis: %d' % max_word_count_hypo)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Null word embeddings: -1\n",
            "Found 2163\n",
            "Total: 2185\n",
            "Max word text: 28\n",
            "Max word hypothesis: 32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Su4IQn5iQ4cs",
        "colab_type": "code",
        "outputId": "b9b7c1b7-67ff-45c5-83ed-808bd939e5bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "s1_data = pad_sequences(sentence1_word_sequences, maxlen = max_seq_length)\n",
        "s2_data = pad_sequences(sentence2_word_sequences, maxlen = max_seq_length)\n",
        "s1_dataValid = pad_sequences(valid_sentence1_word_sequences, maxlen = max_seq_length)\n",
        "s2_dataValid = pad_sequences(valid_sentence2_word_sequences, maxlen = max_seq_length)\n",
        "\n",
        "\n",
        "#labels = np_utils.to_categorical(le.fit_transform(train[\"entailment_judgment\"].values)).astype(\"int64\")\n",
        "#labelsValid = np_utils.to_categorical(le.fit_transform(valid[\"entailment_judgment\"].values)).astype(\"int64\")\n",
        "\n",
        "\n",
        "\n",
        "print('Shape of sentence1 tensor:', s1_data.shape)\n",
        "print('Shape of sentence2 tensor:', s2_data.shape)\n",
        "print('Shape of label tensor:', labels.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of sentence1 tensor: (4500, 20)\n",
            "Shape of sentence2 tensor: (4500, 20)\n",
            "Shape of label tensor: (4500, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WiSmSQq7Q4cv",
        "colab_type": "code",
        "outputId": "34bceb14-c291-4317-bd5e-bc13907efe82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "cell_type": "code",
      "source": [
        "print('One sample')\n",
        "\n",
        "print('Text: ')\n",
        "print( train_sentence1[0] )\n",
        "\n",
        "print('Word sequence: ')\n",
        "print( sentence1_word_sequences[0] )\n",
        "\n",
        "print('Pad: ')\n",
        "print( s1_data[0] )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "One sample\n",
            "Text: \n",
            "A group of kids is playing in a yard and an old man is standing in the background\n",
            "Word sequence: \n",
            "[1, 63, 10, 114, 2, 12, 5, 1, 212, 6, 19, 271, 4, 2, 21, 5, 3, 213]\n",
            "Pad: \n",
            "[  0   0   1  63  10 114   2  12   5   1 212   6  19 271   4   2  21   5\n",
            "   3 213]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FNHgkPs2Q4cy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Helper methods."
      ]
    },
    {
      "metadata": {
        "id": "BET_Zz9xQ4cy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "eps = 1e-6\n",
        "\n",
        "def precision(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def recall(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def fbeta_score(y_true, y_pred, beta=1):\n",
        "    if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:\n",
        "        return 0\n",
        "    p = precision(y_true, y_pred)\n",
        "    r = recall(y_true, y_pred)\n",
        "    bb = beta ** 2\n",
        "    fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n",
        "    return fbeta_score\n",
        "\n",
        "\n",
        "def cosine_distance(y1, y2):\n",
        "    mult =  tf.multiply(y1, y2)\n",
        "    cosine_numerator = tf.reduce_sum( mult, axis = -1)\n",
        "    y1_norm = tf.sqrt(tf.maximum(tf.reduce_sum(tf.square(y1), axis=-1 ), eps) ) \n",
        "    y2_norm = tf.sqrt(tf.maximum(tf.reduce_sum(tf.square(y2), axis=-1 ), eps) ) \n",
        "    return cosine_numerator / y1_norm / y2_norm\n",
        "\n",
        "def cal_relevancy_matrix(text_vector, hypo_vector):\n",
        "    text_vector_tmp = tf.expand_dims(text_vector, 1) # [batch_size, 1, question_len, dim]\n",
        "    hypo_vector_tmp = tf.expand_dims(hypo_vector, 2) # [batch_size, passage_len, 1, dim]\n",
        "    relevancy_matrix = cosine_distance(text_vector_tmp, hypo_vector_tmp) # [batch_size, passage_len, question_len]\n",
        "    return relevancy_matrix\n",
        "\n",
        "def mask_relevancy_matrix(relevancy_matrix, text_mask, hypo_mask):\n",
        "    relevancy_matrix = tf.multiply(relevancy_matrix, K.expand_dims(text_mask, 1))\n",
        "    relevancy_matrix = tf.multiply(relevancy_matrix, K.expand_dims(hypo_mask, 2))\n",
        "    return relevancy_matrix\n",
        "\n",
        "def max_mean_pooling(repres, cosine_matrix):\n",
        "    \n",
        "    repres.append(tf.reduce_max(cosine_matrix, axis = 2, keep_dims = True))\n",
        "    repres.append(tf.reduce_mean(cosine_matrix, axis = 2, keep_dims = True))\n",
        "\n",
        "    return repres\n",
        "\n",
        "def matching_layer(inputs):\n",
        "    forward_relevancy_matrix = cal_relevancy_matrix(inputs[0], inputs[2])\n",
        "    backward_relevancy_matrix = cal_relevancy_matrix(inputs[1], inputs[3])\n",
        "\n",
        "    representation = []\n",
        "\n",
        "    max_mean_pooling(representation, forward_relevancy_matrix)\n",
        "    max_mean_pooling(representation, backward_relevancy_matrix)\n",
        "    \n",
        "    return representation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vUAgat75Q4c1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Matching layer"
      ]
    },
    {
      "metadata": {
        "id": "7cvU0pxoQ4c2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MatchLayer(Layer):\n",
        "\n",
        "    def __init__(self, dim, seq_length, **kwargs):\n",
        "        super(MatchLayer, self).__init__(**kwargs)\n",
        "        self.supports_masking = True\n",
        "        self.dim = dim\n",
        "        self.seq_length = seq_length\n",
        "        \n",
        "    def build(self, input_shape):\n",
        "        if not isinstance(input_shape, list):\n",
        "            raise ValueError('`MatchLayer` layer should be called '\n",
        "                             'on a list of inputs')\n",
        "        \n",
        "        if all([shape is None for shape in input_shape]):\n",
        "            return\n",
        "        \n",
        "        super(MatchLayer, self).build(input_shape)  # Be sure to call this somewhere!\n",
        "\n",
        "    def call(self, inputs):\n",
        "        if not isinstance(inputs, list):\n",
        "            raise ValueError('A `MatchLayer` layer should be called ')\n",
        "        \n",
        "        return matching_layer(inputs)\n",
        "    \n",
        "    def compute_output_shape(self, input_shape):\n",
        "        if not isinstance(input_shape, list):\n",
        "            raise ValueError('A `MatchLayer` layer should be called '\n",
        "                             'on a list of inputs.')\n",
        "        \n",
        "        input_shapes = input_shape\n",
        "        output_shape = list(input_shapes[0])\n",
        "                             \n",
        "        return [ (None, output_shape[1] , 1) ] * 4 \n",
        "    \n",
        "    def get_config(self):\n",
        "        config = {\n",
        "\n",
        "        }\n",
        "        base_config = super(MatchLayer, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "    \n",
        "class MaxPoolingLayer(Layer):\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(MaxPoolingLayer, self).__init__(**kwargs)\n",
        "        \n",
        "    def build(self, input_shape):\n",
        "        super(MaxPoolingLayer, self).build(input_shape)\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        return max_mean_pooling([], inputs)\n",
        "    \n",
        "    def compute_output_shape(self, input_shape):            \n",
        "        output_shape = list(input_shape)\n",
        "        return [ (None, output_shape[1] , 1) ] * 2\n",
        "    \n",
        "    def compute_mask(self, inputs, mask):\n",
        "        return [mask, mask]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7CwmikhEQ4c5",
        "colab_type": "code",
        "outputId": "2a2029de-8a8f-41f1-8261-0e0a714e82ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "cell_type": "code",
      "source": [
        "models = {};\n",
        "\n",
        "def word_context(input, name):\n",
        "    embedding = Embedding(words_len + 1,\n",
        "                     embedding_dim,\n",
        "                     weights = [word_embedding_matrix],\n",
        "                     input_length = max_seq_length,\n",
        "                     trainable = False,\n",
        "                     name = name + '_embedding')(input)\n",
        "    \n",
        "    word = Dropout(0.1)(embedding)\n",
        "\n",
        "    context = Bidirectional(LSTM(100, return_sequences = True),\n",
        "                            merge_mode = None,\n",
        "                            name = name + '_context')(word)\n",
        "    \n",
        "    return (word, context)\n",
        "\n",
        "def create_model():\n",
        "    \n",
        "    sentence1_input = Input(shape=(max_seq_length,), dtype='int32', name = 'text')\n",
        "    sentence2_input = Input(shape=(max_seq_length,), dtype='int32', name = 'hypothesis')\n",
        "    \n",
        "    (text_embedding, text_context) = word_context(sentence1_input, 'text')\n",
        "    (hypo_embedding, hypo_context) = word_context(sentence2_input, 'hypothesis')\n",
        "\n",
        "    left_context = []\n",
        "    left_context.extend(hypo_context)\n",
        "    left_context.extend(text_context)\n",
        "    \n",
        "    left_match = MatchLayer(embedding_dim, max_seq_length)( left_context )\n",
        "    \n",
        "    right_context = []\n",
        "    right_context.extend(text_context)\n",
        "    right_context.extend(hypo_context)\n",
        "    \n",
        "    right_match = MatchLayer(embedding_dim, max_seq_length)( right_context )\n",
        "    \n",
        "    cosine_left = Lambda(lambda x_input: cal_relevancy_matrix(x_input[0], x_input[1]))( [text_embedding, hypo_embedding] )\n",
        "    cosine_right = Lambda(lambda cosine: tf.transpose(cosine, perm=[0,2,1]))( cosine_left )\n",
        "    \n",
        "    left_representation = MaxPoolingLayer()( cosine_left )\n",
        "    right_representation = MaxPoolingLayer()( cosine_right )\n",
        "    \n",
        "    left_representation.extend( left_match )\n",
        "    right_representation.extend( right_match ) \n",
        "    \n",
        "    left = concatenate(left_representation, axis = 2)\n",
        "    left = Dropout(0.1)(left)\n",
        "    \n",
        "    right = concatenate(right_representation, axis = 2)\n",
        "    right = Dropout(0.1)(right)\n",
        "    \n",
        "\n",
        "    aggregation_left = Bidirectional(LSTM(100),\n",
        "                            name = 'aggregation_text_context')(left)\n",
        "    \n",
        "    aggregation_right = Bidirectional(LSTM(100),\n",
        "                            name = 'aggregation_hypo_context')(right)\n",
        "    \n",
        "    aggregation = concatenate([aggregation_left, aggregation_right], axis = -1)\n",
        "                               \n",
        "    pred = Dense(200, activation = 'tanh', name = 'tanh_prediction')(aggregation)\n",
        "    pred = Dense(1, activation = 'sigmoid', name = 'sigmoid_prediction')(pred)\n",
        "    \n",
        "    optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "    \n",
        "    model = Model(inputs=[sentence1_input, sentence2_input], outputs = pred)\n",
        "    model.compile(loss = 'mean_squared_error', \n",
        "              optimizer = optimizer,\n",
        "              metrics = ['mse'])\n",
        "    \n",
        "    print('Model created')\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "models['adam'] = create_model()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From <ipython-input-17-56408f122e2d>:45: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "Model created\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VLrVviOrQ4c-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train Model"
      ]
    },
    {
      "metadata": {
        "id": "S3Ad6hIrXXb2",
        "colab_type": "code",
        "outputId": "003b3933-3530-4e33-f7cf-7549b529a783",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "results = []\n",
        "for name, model in models.items():\n",
        "    callbacks = [\n",
        "        BaseLogger(),\n",
        "        ReduceLROnPlateau(monitor = 'val_loss', factor=0.2, patience=5, min_lr=0.001),\n",
        "        TensorBoard(log_dir='./' + model_name + '-' + name + '-logs', histogram_freq=0, write_graph=True, write_images=True),\n",
        "        ModelCheckpoint(model_name + '-' + name + '-checkpoint-weights.{epoch:02d}-{val_mean_squared_error:.2f}.hdf5', monitor='val_mean_squared_error', save_best_only=True)\n",
        "    ]\n",
        "    \n",
        "    start_time = time.time()\n",
        "    print('')\n",
        "    print('Start learning %s at %d' % (name, start_time))\n",
        "    print('Epochs: %d' % epochs)\n",
        "    print('Batch size: %d' % batch_size)\n",
        "\n",
        "    history = model.fit([s1_data, s2_data],\n",
        "                        labels,\n",
        "                        epochs = 10,\n",
        "                        batch_size = batch_size,\n",
        "                        validation_data=([s1_dataValid, s2_dataValid], labelsValid),\n",
        "                        shuffle = True, #True,\n",
        "                        verbose = 2,\n",
        "                        callbacks = callbacks)\n",
        "\n",
        "    model.save(model_name + '-' + name + '-model.h5')\n",
        "    model.save_weights(model_name + '-' + name + '-weights.h5')\n",
        "\n",
        "    end_time = time.time()\n",
        "    average_time_per_epoch = (end_time - start_time) / epochs\n",
        "    results.append((history, average_time_per_epoch))\n",
        "    \n",
        "    print('Time: %d' % (end_time - start_time))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Start learning adam at 1553233953\n",
            "Epochs: 10\n",
            "Batch size: 32\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "Train on 4500 samples, validate on 500 samples\n",
            "Epoch 1/10\n",
            " - 45s - loss: 0.0539 - mean_squared_error: 0.0539 - val_loss: 0.0378 - val_mean_squared_error: 0.0378\n",
            "Epoch 2/10\n",
            " - 38s - loss: 0.0417 - mean_squared_error: 0.0417 - val_loss: 0.0339 - val_mean_squared_error: 0.0339\n",
            "Epoch 3/10\n",
            " - 38s - loss: 0.0324 - mean_squared_error: 0.0324 - val_loss: 0.0339 - val_mean_squared_error: 0.0339\n",
            "Epoch 4/10\n",
            " - 38s - loss: 0.0256 - mean_squared_error: 0.0256 - val_loss: 0.0322 - val_mean_squared_error: 0.0322\n",
            "Epoch 5/10\n",
            " - 38s - loss: 0.0215 - mean_squared_error: 0.0215 - val_loss: 0.0358 - val_mean_squared_error: 0.0358\n",
            "Epoch 6/10\n",
            " - 38s - loss: 0.0184 - mean_squared_error: 0.0184 - val_loss: 0.0316 - val_mean_squared_error: 0.0316\n",
            "Epoch 7/10\n",
            " - 38s - loss: 0.0159 - mean_squared_error: 0.0159 - val_loss: 0.0378 - val_mean_squared_error: 0.0378\n",
            "Epoch 8/10\n",
            " - 38s - loss: 0.0145 - mean_squared_error: 0.0145 - val_loss: 0.0320 - val_mean_squared_error: 0.0320\n",
            "Epoch 9/10\n",
            " - 38s - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0305 - val_mean_squared_error: 0.0305\n",
            "Epoch 10/10\n",
            " - 38s - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.0319 - val_mean_squared_error: 0.0319\n",
            "Time: 398\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "49C1lal7Q4dM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Testing\n"
      ]
    },
    {
      "metadata": {
        "id": "89ZtyaoaQ4dO",
        "colab_type": "code",
        "outputId": "394df9bb-faf7-4151-f8c5-b641647ad82f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "test_s1_word_sequences = tokenizer.texts_to_sequences(test['sentence_A'].values.tolist())\n",
        "test_s2_word_sequences = tokenizer.texts_to_sequences(test['sentence_B'].values.tolist())\n",
        "\n",
        "test_s1_data = pad_sequences(test_s1_word_sequences, maxlen = max_seq_length)\n",
        "test_s2_data = pad_sequences(test_s2_word_sequences, maxlen = max_seq_length)\n",
        "test_labels = test[\"relatedness_score\"]\n",
        "\n",
        "print('Shape of test sentence1 tensor:', test_s1_data.shape)\n",
        "print('Shape of test sentence2 tensor:', test_s2_data.shape)\n",
        "print('Shape of test label tensor:', test_labels.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of test sentence1 tensor: (4927, 20)\n",
            "Shape of test sentence2 tensor: (4927, 20)\n",
            "Shape of test label tensor: (4927,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cvOxfHsxm_9l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "e = np.reshape(test_labels, (-1,1))\n",
        "scaler1 = MinMaxScaler()\n",
        "scaler1.fit(e)\n",
        "test_labels = pd.DataFrame(scaler1.transform(e))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vRsPG2Usex5s",
        "colab_type": "code",
        "outputId": "ac70e4c9-e8ba-4d2b-935e-5eaff18369c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "for name, model in models.items():\n",
        "    print('')\n",
        "    print('Model %s' % name)\n",
        "    \n",
        "    test_pred = model.predict([test_s1_data, test_s2_data], batch_size=128)\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Model adam\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XfhSXjw1Q4dh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "output= list()\n",
        "for x in test_pred:\n",
        "  output.append(x[0])\n",
        "\n",
        "test[\"Actual Output\"] = output\n",
        "test[\"normalized label\"] = labelsTest\n",
        "test.to_excel(\"output.xlsx\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p9eMqLMPQ4dj",
        "colab_type": "code",
        "outputId": "60554ce5-bbfa-4e6a-bfaa-964d352041d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "numpy.corrcoef(test['normalized label'], test['Actual Output'])[0, 1]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7249025097246602"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "MWdTvxStQ4dm",
        "colab_type": "code",
        "outputId": "50ffe926-c6c0-4a9e-bdcf-15d023040089",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# calculate the spearman's correlation between two variables\n",
        "from numpy.random import rand\n",
        "from numpy.random import seed\n",
        "from scipy.stats import spearmanr\n",
        "# seed random number generator\n",
        "seed(1)\n",
        "\n",
        "# calculate spearman's correlation\n",
        "coef, p = spearmanr(test['normalized label'], test['Actual Output'])\n",
        "print('Spearmans correlation coefficient: %.3f' % coef)\n",
        "print('p: %.3f' % p)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Spearmans correlation coefficient: 0.661\n",
            "p: 0.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TI9T6x_Q1UKr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "output = np.reshape(test['Actual Output'], (-1,1))\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(1, 5))\n",
        "scaler.fit(abc)\n",
        "output = pd.DataFrame(scaler.transform(abc))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VNcp2aP3pZ2L",
        "colab_type": "code",
        "outputId": "8be06592-f2c2-4abe-a1a9-171fab1e8a2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1969
        }
      },
      "cell_type": "code",
      "source": [
        "output\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.678849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.292381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.160466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.654096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.639315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3.631471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3.310823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2.780419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2.872915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>4.448955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>3.923423</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>4.497966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>4.933707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>4.814761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2.978826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>4.186458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>4.256161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>4.803111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>4.548743</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>4.167841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>3.714634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>4.004657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>3.260273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>4.211822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>4.431656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>4.557111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>3.851687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>3.783812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>3.415722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>3.587758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4897</th>\n",
              "      <td>2.901457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4898</th>\n",
              "      <td>3.435710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4899</th>\n",
              "      <td>1.949300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4900</th>\n",
              "      <td>2.952717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4901</th>\n",
              "      <td>2.072168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4902</th>\n",
              "      <td>1.830018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4903</th>\n",
              "      <td>1.668460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4904</th>\n",
              "      <td>2.681850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4905</th>\n",
              "      <td>1.693045</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4906</th>\n",
              "      <td>3.417286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4907</th>\n",
              "      <td>3.858623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4908</th>\n",
              "      <td>1.786129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4909</th>\n",
              "      <td>2.819527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4910</th>\n",
              "      <td>2.469724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4911</th>\n",
              "      <td>2.841283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4912</th>\n",
              "      <td>1.269231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4913</th>\n",
              "      <td>2.451915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4914</th>\n",
              "      <td>2.356436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4915</th>\n",
              "      <td>1.584942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4916</th>\n",
              "      <td>1.314434</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4917</th>\n",
              "      <td>3.389637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4918</th>\n",
              "      <td>2.697695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4919</th>\n",
              "      <td>3.433243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4920</th>\n",
              "      <td>3.022288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4921</th>\n",
              "      <td>3.298340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4922</th>\n",
              "      <td>2.834569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4923</th>\n",
              "      <td>1.917250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4924</th>\n",
              "      <td>1.506722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4925</th>\n",
              "      <td>2.522099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4926</th>\n",
              "      <td>1.939851</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4927 rows  1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             0\n",
              "0     2.678849\n",
              "1     4.292381\n",
              "2     3.160466\n",
              "3     4.654096\n",
              "4     4.639315\n",
              "5     3.631471\n",
              "6     3.310823\n",
              "7     2.780419\n",
              "8     2.872915\n",
              "9     4.448955\n",
              "10    3.923423\n",
              "11    4.497966\n",
              "12    4.933707\n",
              "13    4.814761\n",
              "14    2.978826\n",
              "15    4.186458\n",
              "16    4.256161\n",
              "17    4.803111\n",
              "18    4.548743\n",
              "19    4.167841\n",
              "20    3.714634\n",
              "21    4.004657\n",
              "22    3.260273\n",
              "23    4.211822\n",
              "24    4.431656\n",
              "25    4.557111\n",
              "26    3.851687\n",
              "27    3.783812\n",
              "28    3.415722\n",
              "29    3.587758\n",
              "...        ...\n",
              "4897  2.901457\n",
              "4898  3.435710\n",
              "4899  1.949300\n",
              "4900  2.952717\n",
              "4901  2.072168\n",
              "4902  1.830018\n",
              "4903  1.668460\n",
              "4904  2.681850\n",
              "4905  1.693045\n",
              "4906  3.417286\n",
              "4907  3.858623\n",
              "4908  1.786129\n",
              "4909  2.819527\n",
              "4910  2.469724\n",
              "4911  2.841283\n",
              "4912  1.269231\n",
              "4913  2.451915\n",
              "4914  2.356436\n",
              "4915  1.584942\n",
              "4916  1.314434\n",
              "4917  3.389637\n",
              "4918  2.697695\n",
              "4919  3.433243\n",
              "4920  3.022288\n",
              "4921  3.298340\n",
              "4922  2.834569\n",
              "4923  1.917250\n",
              "4924  1.506722\n",
              "4925  2.522099\n",
              "4926  1.939851\n",
              "\n",
              "[4927 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "KJN42VLb_awH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}